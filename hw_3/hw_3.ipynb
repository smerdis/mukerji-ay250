{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interaction with the World Homework (#3)\n",
    "Python Computing for Data Science (c) J Bloom, UC Berkeley 2018\n",
    "\n",
    "Due Tuesday 2pm, Feb 20, 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Monty: The Python Siri\n",
    "\n",
    "Let's make a Siri-like program (call it Monty!) with the following properties:\n",
    "   - record your voice command\n",
    "   - use a webservice to parse that sound file into text\n",
    "   - based on what the text, take three different types of actions:\n",
    "       - send an email to yourself\n",
    "       - do some math\n",
    "       - tell a joke\n",
    "\n",
    "So for example, if you say \"Monty: email me with subject hello and body goodbye\", it will email you with the appropriate subject and body. If you say \"Monty: tell me a joke\" then it will go to the web and find a joke and print it for you. If you say, \"Monty: calculate two times three\" it should response with printing the number 6.\n",
    "\n",
    "Hint: you can use speed-to-text apps like Houndify (or, e.g., Google Speech https://cloud.google.com/speech/) to return the text (but not do the actions). You'll need to sign up for a free API and then follow documentation instructions for using the service within Python. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, io\n",
    "import pyaudio, wave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "WAVE_OUTPUT_FILENAME = \"new2.wav\"\n",
    "chunk = 1024\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 1\n",
    "RATE = 44100\n",
    "RECORD_SECONDS = 5\n",
    "\n",
    "def record(WAVE_OUTPUT_FILENAME = \"new2.wav\", chunk = 1024, \n",
    "       FORMAT = pyaudio.paInt16, CHANNELS = 1, RATE = 44100, RECORD_SECONDS = 5):\n",
    "    p = pyaudio.PyAudio()\n",
    "    stream = p.open(format = FORMAT, channels = CHANNELS,\n",
    "                    rate = RATE, input = True,\n",
    "                    frames_per_buffer = chunk)\n",
    "    all = []\n",
    "    for i in range(0, int(RATE / chunk * RECORD_SECONDS)):\n",
    "        data = stream.read(chunk)\n",
    "        all.append(data)\n",
    "    print(\"* done recording\")\n",
    "    stream.close()\n",
    "    p.terminate()\n",
    "    data = b\"\".join(all)\n",
    "    with wave.open(WAVE_OUTPUT_FILENAME, \"wb\") as wf:\n",
    "        wf.setnchannels(CHANNELS)\n",
    "        wf.setsampwidth(p.get_sample_size(FORMAT))\n",
    "        wf.setframerate(RATE)\n",
    "        wf.writeframes(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -lat |head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!open new2.wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = '/Users/smerdis/service-account-file.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transcribe_file(speech_file):\n",
    "    \"\"\"Transcribe the given audio file.\"\"\"\n",
    "    from google.cloud import speech\n",
    "    from google.cloud.speech import enums\n",
    "    from google.cloud.speech import types\n",
    "    client = speech.SpeechClient()\n",
    "\n",
    "    with io.open(speech_file, 'rb') as audio_file:\n",
    "        content = audio_file.read()\n",
    "\n",
    "    audio = types.RecognitionAudio(content=content)\n",
    "    config = types.RecognitionConfig(\n",
    "        encoding=enums.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "        sample_rate_hertz=44100,\n",
    "        language_code='en-US')\n",
    "\n",
    "    response = client.recognize(config, audio)\n",
    "    # Each result is for a consecutive portion of the audio. Iterate through\n",
    "    # them to get the transcripts for the entire audio file.\n",
    "    for result in response.results:\n",
    "        # The first alternative is the most likely one for this portion.\n",
    "        print('Transcript: {}'.format(result.alternatives[0].transcript))\n",
    "        \n",
    "    return response.results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = transcribe_file(WAVE_OUTPUT_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "command = results[0].alternatives[0].transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tell_joke():\n",
    "    \"\"\"Function that gets a joke off the internet and returns it.\"\"\"\n",
    "    raise NotImplementedError(\"TODO\")\n",
    "    \n",
    "def do_calculation(command):\n",
    "    \"\"\"Function that accepts a command to do math and returns the result.\n",
    "    \n",
    "    Probably just gonna throw the calculation at google and try to return whatever is in the calculator box.\"\"\"\n",
    "    from urllib.parse import urlencode\n",
    "    import bs4\n",
    "    import requests\n",
    "    \n",
    "    words = command.split()\n",
    "    the_calculation = ' '.join(words[2:])\n",
    "    print(the_calculation)\n",
    "    \n",
    "    query = {'q':the_calculation}\n",
    "    url_values = urlencode(query)\n",
    "    \n",
    "    url = f\"https://www.google.com/search?{url_values}\"\n",
    "    req = requests.get(url)\n",
    "    #print(req.text)\n",
    "    soup = bs4.BeautifulSoup(req.text, \"lxml\")\n",
    "    print(list(x.get_text() for x in soup.find_all(\"h2\", class_=\"r\")))\n",
    "    \n",
    "def send_email(command):\n",
    "    \"\"\"Function that accepts a command to send an email with a specifiable subject and body, then does so.\"\"\"\n",
    "    raise NotImplementedError(\"TODO\")\n",
    "\n",
    "def act(command):\n",
    "    \"\"\"Function that takes the transcript of a command, determines if it is valid, and acts accordingly if so.\"\"\"\n",
    "    words = command.split()\n",
    "    # I decided to just use a simple heuristic to dispatch the 3 actions specified in the problem\n",
    "    # rather than getting into natural language processing and other heavyweight approaches\n",
    "    if (words[0] != \"Monty\") and (words[0] != \"Monte\"):\n",
    "        print(\"Commands must begin by addresing Monty by name. For example: \\\"Monty, tell me a joke.\\\"\")\n",
    "    elif \"email\" in command: # if we see the word email, assume we are to send one\n",
    "        # putting this first allows the email to contain the words \"calculate\" or \"tell me a joke\"...\n",
    "        print(\"Gonna send you an email, aw yiss.\")\n",
    "        send_email(command)\n",
    "    elif \"calculate\" in command:\n",
    "        print(\"Gonna do some math, aw yiss.\")\n",
    "        do_calculation(command)\n",
    "    elif (\"tell\" in command and \"joke\" in command):\n",
    "        print(\"Gonna tell you  a joke, aw yiss.\")\n",
    "        tell_joke()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "act(command)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Write a program that identifies musical notes from sound (AIFF) files. \n",
    "\n",
    "  - Run it on the supplied sound files (12) and report your program’s results. \n",
    "  - Use the labeled sounds (4) to make sure it works correctly. The provided sound files contain 1-3 simultaneous notes from different organs.\n",
    "  - Save copies of any example plots to illustrate how your program works.\n",
    "  \n",
    "  https://piazza.com/berkeley/spring2018/ay250class13410/resources -> Homeworks -> hw3_sound_files.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hints: You’ll want to decompose the sound into a frequency power spectrum. Use a Fast Fourier Transform. Be care about “unpacking” the string hexcode into python data structures. The sound files use 32 bit data. Play around with what happens when you convert the string data to other integer sizes, or signed vs unsigned integers. Also, beware of harmonics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
